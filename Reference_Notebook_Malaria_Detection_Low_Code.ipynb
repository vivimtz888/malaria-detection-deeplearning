{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1BMt4ja28FM"
      },
      "source": [
        "# **Malaria Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCiPVBNbA0Wh"
      },
      "source": [
        "##<b>Problem Definition</b>\n",
        "**The context:** Why is this problem important to solve?<br>\n",
        "**The objectives:** What is the intended goal?<br>\n",
        "**The key questions:** What are the key questions that need to be answered?<br>\n",
        "**The problem formulation:** What is it that we are trying to solve using data science?\n",
        "\n",
        "## <b>Data Description </b>\n",
        "\n",
        "There are a total of 24,958 train and 2,600 test images (colored) that we have taken from microscopic images. These images are of the following categories:<br>\n",
        "\n",
        "\n",
        "**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria<br>\n",
        "**Uninfected:** The uninfected cells are free of the Plasmodium parasites<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGsTRO4XBWKn"
      },
      "source": [
        "## <b>Important Notes</b>\n",
        "\n",
        "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise. \n",
        "\n",
        "- In the notebook, there are markdowns cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
        "\n",
        "- The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.\n",
        "\n",
        "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
        "\n",
        "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDM89XHyCxrA"
      },
      "source": [
        "###<b> Mounting the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQi_degJC3dm",
        "outputId": "4cec091d-4b73-4ccd-90e5-297bc640bded"
      },
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC8-yLUUCcWh"
      },
      "source": [
        "### <b>Loading libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries required to load the data\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# To ignore warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Remove the limit from the number of displayed columns and rows. It helps to see the entire dataframe while printing it\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "pd.set_option(\"display.max_rows\", 200)"
      ],
      "metadata": {
        "id": "iixNDZWs1ZPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqJk2XpCnJi"
      },
      "source": [
        "### <b>Let us load the data</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syvBdMlDTsr"
      },
      "source": [
        "**Note:** \n",
        "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
        "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufMU62DICjLV"
      },
      "source": [
        "# Storing the path of the data file from the Google drive\n",
        "path = '/content/drive/MyDrive/cell_images.zip'\n",
        "\n",
        "# The data is provided as a zip file so we need to extract the files from the zip file\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW3fDq7gF4Hw"
      },
      "source": [
        "The extracted folder has different folders for train and test data which further contains the different sizes of images for parasitized and uninfected cells within the respective folder name. \n",
        "\n",
        "The size of all images must be the same and should be converted to 4D arrays so that they can be used as an input for the convolutional neural network. Also, we need to create the labels for both types of images to be able to train and test the model. \n",
        "\n",
        "Let's do the same for the training data first and then we will use the same code for the test data as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjK02uF1DXdW"
      },
      "source": [
        "# Storing the path of the extracted \"train\" folder \n",
        "train_dir = '/content/cell_images/train'\n",
        "\n",
        "# Size of image so that each image has the same size\n",
        "SIZE = 64\n",
        "\n",
        "# Empty list to store the training images after they are converted to NumPy arrays\n",
        "train_images = []\n",
        "\n",
        "# Empty list to store the training labels (0 - uninfected, 1 - parasitized)\n",
        "train_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JNY4tSvDXgn"
      },
      "source": [
        "# We will run the same code for \"parasitized\" as well as \"uninfected\" folders within the \"train\" folder\n",
        "for folder_name in ['/parasitized/', '/uninfected/']:\n",
        "    \n",
        "    # Path of the folder\n",
        "    images_path = os.listdir(train_dir + folder_name)\n",
        "\n",
        "    for i, image_name in enumerate(images_path):\n",
        "    \n",
        "        try:\n",
        "    \n",
        "            # Opening each image using the path of that image\n",
        "            image = Image.open(train_dir + folder_name + image_name)\n",
        "\n",
        "            # Resizing each image to (64, 64)\n",
        "            image = image.resize((SIZE, SIZE))\n",
        "\n",
        "            # Converting images to arrays and appending that array to the empty list defined above\n",
        "            train_images.append(np.array(image))\n",
        "\n",
        "            # Creating labels for parasitized and uninfected images\n",
        "            if folder_name == '/parasitized/':\n",
        "            \n",
        "                train_labels.append(1)\n",
        "           \n",
        "            else:\n",
        "           \n",
        "                train_labels.append(0)\n",
        "        \n",
        "        except Exception:\n",
        "       \n",
        "            pass       \n",
        "\n",
        "# Converting lists to arrays\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "train_labels = np.array(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfwXIsK_DXiv"
      },
      "source": [
        "# Storing the path of the extracted \"test\" folder \n",
        "test_dir = '/content/cell_images/test'\n",
        "\n",
        "# Size of image so that each image has the same size (it must be same as the train image size)\n",
        "SIZE = 64\n",
        "\n",
        "# Empty list to store the testing images after they are converted to NumPy arrays\n",
        "test_images = []\n",
        "\n",
        "# Empty list to store the testing labels (0 - uninfected, 1 - parasitized)\n",
        "test_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My6pm3AFDXk9"
      },
      "source": [
        "# We will run the same code for \"parasitized\" as well as \"uninfected\" folders within the \"test\" folder\n",
        "for folder_name in ['/parasitized/', '/uninfected/']:\n",
        "    \n",
        "    # Path of the folder\n",
        "    images_path = os.listdir(test_dir + folder_name)\n",
        "\n",
        "    for i, image_name in enumerate(images_path):\n",
        "\n",
        "        try:\n",
        "            # Opening each image using the path of that image\n",
        "            image = Image.open(test_dir + folder_name + image_name)\n",
        "            \n",
        "            # Resizing each image to (64, 64)\n",
        "            image = image.resize((SIZE, SIZE))\n",
        "            \n",
        "            # Converting images to arrays and appending that array to the empty list defined above\n",
        "            test_images.append(np.array(image))\n",
        "            \n",
        "            # Creating labels for parasitized and uninfected images\n",
        "            if folder_name == '/parasitized/':\n",
        "\n",
        "                test_labels.append(1)\n",
        "\n",
        "            else:\n",
        "\n",
        "                test_labels.append(0)\n",
        "\n",
        "        except Exception:\n",
        "\n",
        "            pass       \n",
        "\n",
        "# Converting lists to arrays\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_rxFT9iH7pR"
      },
      "source": [
        "###<b> Checking the shape of train and test images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of images"
      ],
      "metadata": {
        "id": "LA8HJmQp1hU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3AiiutGIEoy"
      },
      "source": [
        "###<b> Checking the shape of train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of labels "
      ],
      "metadata": {
        "id": "UJ_uvmT61rvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3gtgoubINVX"
      },
      "source": [
        "####<b> Observations and insights: _____\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFUMkif7IjlO"
      },
      "source": [
        "### <b>Check the minimum and maximum range of pixel values for train and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gJbhCbMIswX"
      },
      "source": [
        "# Try to use min and max function from numpy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T8WWuSpI6Ih"
      },
      "source": [
        "####<b> Observations and insights: _____\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywUFcLSCPIqz"
      },
      "source": [
        "###<b> Count the number of values in both uninfected and parasitized "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcEb9liBPRlu"
      },
      "source": [
        "# Try to use value_counts to count the values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U71xb2XJe0t"
      },
      "source": [
        "###<b>Normalize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqzvvNS9IvsP"
      },
      "source": [
        "# Try to normalize the train and test images by dividing it by 255 and convert them to float32 using astype function\n",
        "train_images = (___________).astype('float32')\n",
        "\n",
        "test_images = (______________).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAT1eVTrKiDy"
      },
      "source": [
        "####<b> Observations and insights: _____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG4meNZBKZ5r"
      },
      "source": [
        "###<b> Plot to check if the data is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N4qohCFIvvI"
      },
      "source": [
        "# You are free to use bar plot or pie-plot or count plot, etc. to plot the labels of train and test data and check if they are balanced\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGfRJaffLI-C"
      },
      "source": [
        "####<b> Observations and insights: _____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16-Er2edMzsD"
      },
      "source": [
        "### <b>Data Exploration</b>\n",
        "Let's visualize the images from the train data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code will help you in visualizing both the parasitized and uninfected images\n",
        "np.random.seed(42)\n",
        "\n",
        "plt.figure(1, figsize = (16 , 16))\n",
        "\n",
        "for n in range(1, 17):\n",
        "\n",
        "    plt.subplot(4, 4, n)\n",
        "\n",
        "    index = int(np.random.randint(0, train_images.shape[0], 1))\n",
        "\n",
        "    if train_labels[index] == 1: \n",
        "\n",
        "        plt.title('parasitized')\n",
        "\n",
        "    else:\n",
        "        plt.title('uninfected')\n",
        "\n",
        "    plt.imshow(train_images[index])\n",
        "\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "kjhRVQ3-2Pa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnyS_9IcCZLp"
      },
      "source": [
        "####<b> Observations and insights: _____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay4oo5HrTDha"
      },
      "source": [
        "###<b> Similarly visualize the images with subplot(6, 6) and figsize = (12, 12)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKmncZ-fTAdD"
      },
      "source": [
        "# Hint: Have a keen look into the number of iterations that the for loop should iterate\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTG8UaNNNNso"
      },
      "source": [
        "####<b>Observations and insights:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifjZ2G0YN20r"
      },
      "source": [
        "###<b> Plotting the mean images for parasitized and uninfected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN9X0620Iv1a"
      },
      "source": [
        "# Function to find the mean\n",
        "def find_mean_img(full_mat, title):\n",
        "\n",
        "    # Calculate the average\n",
        "    mean_img = np.mean(full_mat, axis = 0)[0]\n",
        "\n",
        "    # Reshape it back to a matrix\n",
        "    plt.imshow(mean_img)\n",
        "\n",
        "    plt.title(f'Average {title}')\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return mean_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4xRQfUOMtm"
      },
      "source": [
        "<b> Mean image for parasitized"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If the label = 1 then the image is parasitised and if the label = 0 then the image is uninfected\n",
        "parasitized_data = []  # Create a list to store the parasitized data\n",
        "\n",
        "for img, label in zip(train_images, train_labels):\n",
        "\n",
        "        if label == 1:\n",
        "              \n",
        "              parasitized_data.append([img])          \n",
        "\n",
        "parasitized_mean = find_mean_img(np.array(parasitized_data), 'Parasitized')   # find the mean"
      ],
      "metadata": {
        "id": "SlgCf1-x2gli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkRt1rYIKE24"
      },
      "source": [
        "<b> Mean image for uninfected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji4w0okiIv6o"
      },
      "source": [
        "# Similarly write the code to find the mean image of uninfected\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp9NP8yqPA69"
      },
      "source": [
        "####<b> Observations and insights: _____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzBagGEzHMHB"
      },
      "source": [
        "### <b>Converting RGB to HSV of Images using OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJFCdE77H1Sg"
      },
      "source": [
        "###<b> Converting the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32iwgGz7Iv-E"
      },
      "source": [
        "import cv2\n",
        "\n",
        "gfx=[]   # to hold the HSV image array\n",
        "\n",
        "for i in np.arange(0, 100, 1):\n",
        "\n",
        "  a = cv2.cvtColor(train_images[i], cv2.COLOR_BGR2HSV)\n",
        "  \n",
        "  gfx.append(a)\n",
        "\n",
        "gfx = np.array(gfx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viewimage = np.random.randint(1, 100, 5)\n",
        "\n",
        "fig, ax = plt.subplots(1, 5, figsize = (18, 18))\n",
        "\n",
        "for t, i in zip(range(5), viewimage):\n",
        "\n",
        "  Title = train_labels[i]\n",
        "\n",
        "  ax[t].set_title(Title)\n",
        "\n",
        "  ax[t].imshow(gfx[i])\n",
        "\n",
        "  ax[t].set_axis_off()\n",
        "  \n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "V3mr2iWd2pMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9a7cFllH794"
      },
      "source": [
        "###<b> Converting the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-kUOULrGpBA"
      },
      "source": [
        "# Similarly you can visualize for the images in the test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq4_3hv6J3ad"
      },
      "source": [
        "####<b>Observations and insights: _____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7x9uDxuJur7"
      },
      "source": [
        "###<b> Processing Images using Gaussian Blurring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgkB_-J2KhBQ"
      },
      "source": [
        "###<b> Gaussian Blurring on train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7GtZThUI6ug"
      },
      "source": [
        "gbx = []  # To hold the blurred images\n",
        "\n",
        "for i in np.arange(0, 100, 1):\n",
        "\n",
        "  b = cv2.GaussianBlur(train_images[i], (5, 5), 0)\n",
        "\n",
        "  gbx.append(b)\n",
        "\n",
        "gbx = np.array(gbx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viewimage = np.random.randint(1, 100, 5)\n",
        "\n",
        "fig, ax = plt.subplots(1, 5, figsize = (18, 18))\n",
        "\n",
        "for t, i in zip(range(5), viewimage):\n",
        "\n",
        "  Title = train_labels[i]\n",
        "\n",
        "  ax[t].set_title(Title)\n",
        "\n",
        "  \n",
        "  ax[t].imshow(gbx[i])\n",
        "  \n",
        "  ax[t].set_axis_off()\n",
        "  \n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "x9qa58ep207S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTsJkRtCKlYZ"
      },
      "source": [
        "###<b> Gaussian Blurring on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbmMGySOKblh"
      },
      "source": [
        "# Similarly you can apply Gaussian blurring for the images in the test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkpR8tQFKplr"
      },
      "source": [
        "####**Observations and insights: _____**\n",
        "\n",
        "**Think About It:** Would blurring help us for this problem statement in any way? What else can we try?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtayck2-Pm3G"
      },
      "source": [
        "###<B>One Hot Encoding on the train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDWl6dVtOMom"
      },
      "source": [
        "# Encoding Train Labels\n",
        "train_labels = to_categorical(____, 2)\n",
        "\n",
        "# Similarly let us try to encode test labels\n",
        "test_labels = to_categorical(_____, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4_ZzqDp8T5w"
      },
      "source": [
        "### **Base Model**\n",
        "\n",
        "**Note:** The Base Model has been fully built and evaluated with all outputs shown to give an idea about the process of the creation and evaluation of the performance of a CNN architecture. A similar process can be followed in iterating to build better-performing CNN architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTMSr0Xw6x3b"
      },
      "source": [
        "###<b> Importing the required libraries for building and training our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8eWxdyDp_ZC"
      },
      "source": [
        "# Clearing backend\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout  \n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmwb4h0h64Km"
      },
      "source": [
        "###<b> Building the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequential model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\", input_shape = (64, 64, 3)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = 2))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = 2))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 2, padding = \"same\", activation = \"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = 2))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(2, activation = \"softmax\")) # 2 represents output layer neurons \n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3LV1Ad_b4_LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sh0OGP268Qm"
      },
      "source": [
        "###<b> Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGRMByKOMyG"
      },
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dt8lFvz6_K6"
      },
      "source": [
        "<b> Using Callbacks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPwUYX3KOM34"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
        "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91af114l7DCt"
      },
      "source": [
        "<b> Fit and train our Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with min batch size as 32 can tune batch size to some factor of 2^power ] \n",
        "history = model.fit(train_images, train_labels, batch_size = 32, callbacks = callbacks, validation_split = 0.2, epochs = 20, verbose = 1)"
      ],
      "metadata": {
        "id": "XysPQsWn5EGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7bDXku7Ib8"
      },
      "source": [
        "###<b> Evaluating the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(test_images, test_labels, verbose = 1)\n",
        "print('\\n', 'Test_Accuracy:-', accuracy[1])"
      ],
      "metadata": {
        "id": "mHbgBrZe5Hqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoNNG_T7PkT"
      },
      "source": [
        "<b> Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pred = model.predict(test_images)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1) \n",
        "\n",
        "y_true = np.argmax(test_labels, axis = 1)\n",
        "\n",
        "# Printing the classification report\n",
        "print(classification_report(y_true, pred))\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "cm = confusion_matrix(y_true, pred)\n",
        "\n",
        "plt.figure(figsize = (8, 5))\n",
        "\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['Uninfected', 'Parasitized'], yticklabels = ['Uninfected', 'Parasitized'])\n",
        "\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mwY1yx095NN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWq4jyPL7f5a"
      },
      "source": [
        "<b>Plotting the train and validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3h5gAwyW05u"
      },
      "source": [
        "# Function to plot train and validation accuracy \n",
        "def plot_accuracy(history):\n",
        "\n",
        "    N = len(history.history[\"accuracy\"])\n",
        "\n",
        "    plt.figure(figsize = (7, 7))\n",
        "\n",
        "    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label = \"train_accuracy\", ls = '--')\n",
        "\n",
        "    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label = \"val_accuracy\", ls = '--')\n",
        "\n",
        "    plt.title(\"Accuracy vs Epoch\")\n",
        "    \n",
        "    plt.xlabel(\"Epochs\")\n",
        "    \n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    \n",
        "    plt.legend(loc=\"upper left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy(history)"
      ],
      "metadata": {
        "id": "PnxxiR-T5PsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGOtxZ10fEIn"
      },
      "source": [
        "\n",
        "\n",
        "* Here we can clearly observe that the training and valiation accuracy are increasing \n",
        "* And we can also notice that validation accuracy is slightly higher than the train accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCDgxiFnXSek"
      },
      "source": [
        "So now let's try to build another model with few more add on layers and try to check if we can try to improve the model. Therefore try to build a model by adding few layers if required and altering the activation functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJeklwR77rs"
      },
      "source": [
        "###<b> Model 1\n",
        "####<b> Trying to improve the performance of our model by adding new layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend.clear_session() # Clearing the backend for new model"
      ],
      "metadata": {
        "id": "J-NnG6Rp9_w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT99NdnzZW3n"
      },
      "source": [
        "###<b> Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TaSet9DONGV"
      },
      "source": [
        "# Creating sequential model\n",
        "model1 = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build the model here and add new layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6cTCOAVZZpI"
      },
      "source": [
        "###<b> Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWcQhKidONIr"
      },
      "source": [
        "model1.compile(loss = __________, optimizer = _______, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PSskadUZhUt"
      },
      "source": [
        "<b> Using Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_T2_sKONMA"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
        "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYLgQK9DZkoc"
      },
      "source": [
        "<b>Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7S7LmVTZjrd"
      },
      "source": [
        "history1 = model1.fit(_____________, __________, batch_size = ______, callbacks = callbacks,  validation_split = ______, epochs = ______, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHABkGRzZwyt"
      },
      "source": [
        "###<b> Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yie1Z-R6Zjt_"
      },
      "source": [
        "accuracy1 = model1.evaluate(_________, _____________, verbose = 1)\n",
        "\n",
        "print('\\n', 'Test_Accuracy:-', accuracy1[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCJEZ6cqZywk"
      },
      "source": [
        "<b> Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmuJFfUjZjws"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roDugWeKaVDW"
      },
      "source": [
        "<b> Plotting the train and the validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JakeVNnbZjzh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsx7jVjaiO9V"
      },
      "source": [
        "###<b>Think about it:</b><br>\n",
        "Now let's build a model with LeakyRelu as the activation function  \n",
        "\n",
        "*  Can the model performance be improved if we change our activation function to LeakyRelu?\n",
        "*  Can BatchNormalization improve our model?\n",
        "\n",
        "Let us try to build a model using BatchNormalization and using LeakyRelu as our activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU4qr7amiXds"
      },
      "source": [
        "###<b> Model 2 with Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOXd_ciyZj2n"
      },
      "source": [
        "backend.clear_session() # Clearing the backend for new model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDMUu-U8vV3"
      },
      "source": [
        "###<b> Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJBcwhtbiu0l"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), padding = 'same'))\n",
        "\n",
        "'''\n",
        "\n",
        "Complete this model using BatchNormalization layers and by using LeakyRelu as the activation function\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "adam = optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9WQ7-cOLIQy"
      },
      "source": [
        "###<b>Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SiRoyZ7LHSL"
      },
      "source": [
        "model2.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOVzX0WTDUEy"
      },
      "source": [
        "<b> Using callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0FcITongxx"
      },
      "source": [
        "'''\n",
        "\n",
        "create the callbacks similarly as done in the base model\n",
        "As callbacks will help us in saving our checkpoints and stopping at an accuracy where the model doesnot seem to improve\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxj3AcS0Dqm8"
      },
      "source": [
        "<b>Fit and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMy-4IGajL31"
      },
      "source": [
        "history2 = model2.fit(train_images, train_labels, batch_size = 32, callbacks = callbacks, validation_split = 0.2, epochs = 20, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9DkuwVYDtc3"
      },
      "source": [
        "<b>Plotting the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILu-oHB_jxGY"
      },
      "source": [
        "# Plotting the accuracies\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSREnGkgDz6N"
      },
      "source": [
        "###<b>Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZGH8gE089Gx"
      },
      "source": [
        "# Evaluate the model to calculate the accuracy\n",
        "\n",
        "accuracy = model2.evaluate(________, ______________, verbose = 1)\n",
        "\n",
        "print('\\n', 'Test_Accuracy:-', accuracy[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiIQnwKaJ27O"
      },
      "source": [
        "####<b>Observations and insights: ____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDL1BQZ7_JxS"
      },
      "source": [
        "<b> Generate the classification report and confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB-CYdwC9V8P"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pred = model2.predict(_______)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1) \n",
        "\n",
        "y_true = np.argmax(________________, axis = 1)\n",
        "\n",
        "# Printing the classification report\n",
        "print(classification_report(______, _______))\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "\n",
        "cm = confusion_matrix(_____, _____)\n",
        "\n",
        "plt.figure(figsize = (8, 5))\n",
        "\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['Uninfected', 'Parasitized'], yticklabels = ['Uninfected', 'Parasitized'])\n",
        "\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUwBBVzuijlU"
      },
      "source": [
        "###**Think About It :**<br>\n",
        "\n",
        "* Can we improve the model with Image Data Augmentation?\n",
        "* References to image data augmentation can be seen below:\n",
        "  *   [Image Augmentation for Computer Vision](https://www.mygreatlearning.com/blog/understanding-data-augmentation/)\n",
        "  *   [How to Configure Image Data Augmentation in Keras?](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYVJZ0Psi0D0"
      },
      "source": [
        "###<b>Model 3 with Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ddfrhcLihpz"
      },
      "source": [
        "backend.clear_session() # Clearing backend for new model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqOnCq3FZ6JG"
      },
      "source": [
        "###<b> Using image data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnvWygv4aAZc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Using ImageDataGenerator to generate images\n",
        "train_datagen = ImageDataGenerator(horizontal_flip = True, \n",
        "                                  zoom_range = 0.5, rotation_range = 30)\n",
        "\n",
        "val_datagen  = ImageDataGenerator()\n",
        "\n",
        "# Flowing training images using train_datagen generator\n",
        "train_generator = train_datagen.flow(x = _______, y = __________, batch_size = 64, seed = 42, shuffle = True)\n",
        "\n",
        "\n",
        "# Flowing validation images using val_datagen generator\n",
        "val_generator =  val_datagen.flow(x = _________, y = _________, batch_size = 64, seed = 42, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cJN07Bbofx"
      },
      "source": [
        "###**Think About It :**<br>\n",
        "\n",
        "*  Check if the performance of the model can be improved by changing different parameters in the ImageDataGenerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341Ilg5McowX"
      },
      "source": [
        "####<B>Visualizing Augmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3BE91RbFBy"
      },
      "source": [
        "# Creating an iterable for images and labels from the training data\n",
        "images, labels = next(train_generator)\n",
        "\n",
        "# Plotting 16 images from the training data\n",
        "fig, axes = plt.subplots(4, 4, figsize = (16, 8))\n",
        "\n",
        "fig.set_size_inches(16, 16)\n",
        "for (image, label, ax) in zip(images, labels, axes.flatten()):\n",
        "\n",
        "    ax.imshow(image)\n",
        "\n",
        "    if label[1] == 1: \n",
        "\n",
        "        ax.set_title('parasitized')\n",
        "\n",
        "    else:\n",
        "\n",
        "        ax.set_title('uninfected')\n",
        "\n",
        "    ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfCMCaAZdK3o"
      },
      "source": [
        "####<b>Observations and insights: ____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrpS4Azamjs4"
      },
      "source": [
        "###<b>Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVELJI8uihsz"
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "# Build the model here\n",
        "# Use this as the optimizer\n",
        "adam = optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "model3.compile(loss = ________________, optimizer = adam, metrics = ['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HrtTMJnEPl"
      },
      "source": [
        "<b>Using Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWPxLvdihvf"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2),\n",
        "             ModelCheckpoint('.mdl_wts.hdf5', monitor = 'val_loss', save_best_only = True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEeOIRrCnMBh"
      },
      "source": [
        "<b> Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_2dSGYMihyk"
      },
      "source": [
        "history3 = model3.fit(train_generator, \n",
        "                                  validation_data = val_generator,\n",
        "                                  batch_size = _____, callbacks = ___________,\n",
        "                                  epochs = 20, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EFWVEUKoM1U"
      },
      "source": [
        "###<B>Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8twGIoxWnrCb"
      },
      "source": [
        "<b>Plot the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjB4IecBih2K"
      },
      "source": [
        "# Potting the accuracies\n",
        "plot_accuracy(_________)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9sBTSvL_Uz-"
      },
      "source": [
        "# Evaluating the model on test data\n",
        "accuracy3 = _________.evaluate(________, ___________, verbose = 1)\n",
        "\n",
        "print('\\n', 'Test_Accuracy:-', accuracy3[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_VDQxXwoe6u"
      },
      "source": [
        "<B>Plotting the classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxdOpuzJoj8l"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obzJSEF5ypj-"
      },
      "source": [
        "<b> Now, let us try to use a pretrained model like VGG16 and check how it performs on our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-GUCjbLHGg"
      },
      "source": [
        "### **Pre-trained model (VGG16)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dH2_XWNLyac"
      },
      "source": [
        "# Clearing backend\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCtAgs1FAxhp"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "vgg = VGG16(include_top = _________, weights = 'imagenet', input_shape = (64, 64, 3))\n",
        "\n",
        "vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDQ7RswtA0jf"
      },
      "source": [
        "transfer_layer = vgg.get_layer('block5_pool')\n",
        "\n",
        "vgg.trainable = False\n",
        "\n",
        "# Add classification layers on top of it  \n",
        "x = Flatten()(transfer_layer.output)  # Flatten the output from the 3rd block of the VGG16 model\n",
        "\n",
        "x = Dense(256, activation = 'relu')(x)\n",
        "\n",
        "# Similarly add a dense layer with 128 neurons\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Add a dense layer with 64 neurons\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "pred = Dense(______, activation = 'softmax')(_____)\n",
        "\n",
        "model4 = Model(vgg.input, pred) # Initializing the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhoug92KFWPa"
      },
      "source": [
        "###<b>Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdJ8C0L5Lkyt"
      },
      "source": [
        "# Compiling the model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBPzjtxcFLQt"
      },
      "source": [
        "<b> using callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS3skmQBR4if"
      },
      "source": [
        "# Adding Callbacks to the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ZeobGmFIOF"
      },
      "source": [
        "<b>Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6sSx39uL1mS"
      },
      "source": [
        "# Fitting the model and running the model for 10 epochs\n",
        "history4 = model4.fit(\n",
        "            __________, ______________,\n",
        "            epochs = _________,\n",
        "            callbacks = _____________,\n",
        "            batch_size = _________,\n",
        "            validation_split = 0.2,\n",
        "            verbose = 1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0WI9dvDFBaR"
      },
      "source": [
        "<b>Plot the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKmS2XyiMBqb"
      },
      "source": [
        "# plotting the accuracies\n",
        "plot_accuracy(__________)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb3jUduI0BNs"
      },
      "source": [
        "###**Observations and insights: _____**\n",
        "\n",
        "*   What can be observed from the validation and train curves?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykl7xLODEoix"
      },
      "source": [
        "###<b> Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxcgkSoivwWf"
      },
      "source": [
        "# Evaluating the model on test data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_lr-dUHE77F"
      },
      "source": [
        "<b>Plotting the classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jns2wf2HMBto"
      },
      "source": [
        "# Plot the confusion matrix and generate a classification report for the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEZPA_mN0tUo"
      },
      "source": [
        "###<b>Think about it:</b>\n",
        "*  What observations and insights can be drawn from the confusion matrix and classification report?\n",
        "*  Choose the model with the best accuracy scores from all the above models and save it as a final model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smzi8y5AEYIi"
      },
      "source": [
        "####<b> Observations and Conclusions drawn from the final model: _____\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6IpgOZ1n-g"
      },
      "source": [
        "**Improvements that can be done:**<br>\n",
        "\n",
        "\n",
        "*  Can the model performance be improved using other pre-trained models or different CNN architecture?\n",
        "*  You can try to build a model using these HSV images and compare them with your other models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJB6yf2EczFk"
      },
      "source": [
        "#### **Insights**\n",
        "\n",
        "####**Refined insights**:\n",
        "- What are the most meaningful insights from the data relevant to the problem?\n",
        "\n",
        "####**Comparison of various techniques and their relative performance**:\n",
        "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
        "\n",
        "####**Proposal for the final solution design**:\n",
        "- What model do you propose to be adopted? Why is this the best solution to adopt?"
      ]
    }
  ]
}